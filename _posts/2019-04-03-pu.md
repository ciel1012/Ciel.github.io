---
layout:     post
title:      "The Graphics Processing Unit"
subtitle:   "\"《Real-Time Rendering 4th》笔记——第三章 图形处理器\""
date:       2019-04-03
author:     "Ciel"
header-img: "img/post-bg-rtr.jpg"
tags:
    - Real-Time Rendering
    - 笔记
---

# The Graphics Processing Unit

> 这章介绍了GPU渲染管线的组成，可编程着色技术的发展过程，以及Vertex Shader、Tessellation Stage、Geometry Shader、Pixel Shader、Merging Stage、Compute Shader。

1. [Data-Parallel Architectures 数据并行处理架构](#数据并行处理架构)

2. [GPU Pipeline Overview GPU渲染管线概述](#gpu渲染管线概述)

3. [The Programmable Shader Stage 可编程着色阶段](#可编程着色阶段)

4. [The Evolution of Programmable Shading and APIs 可编程着色和API的发展](#可编程着色和api的发展)

5. [The Vertex Shader 顶点着色器](#顶点着色器)

6. [The Tessellation Stage 细分阶段](#细分阶段)

7. [The Geomtry Shader 几何着色器](#几何着色器)

8. [The Pixel Shader 像素着色器](#像素着色器)

9. [The Merging Stage 合并阶段](#合并阶段)

10. [The Compute Shader 计算着色器](#计算着色器)

### 数据并行处理架构

- 不同的处理器体系结构使用不同的策略来避免停滞。为了最小化延迟的影响，CPU芯片的大部分由快速本地缓存组成，内存中充满了接下来可能需要的数据。CPU可以有多个处理器，但是每个处理器都以串行方式运行代码（有限的SIMD向量处理是小例外）。CPU还通过使用诸如分支预测、指令重新排序、寄存器重命名和缓存预取等智能技术来避免停机

- GPU的大部分芯片区域用于一组大的处理器，称为着色器内核，通常有数千个。GPU是一个流处理器，它依次处理有序的相似数据。因为一组顶点或像素有这种相似性，GPU可以大规模处理这些并行数据。另一个重要因素是，这些调用尽可能独立，它们不需要调用相邻数据信息，也不共享可写内存位置。这个规则有时会被打破，以允许新的和有用的功能，但是这种例外是以潜在的延迟为代价的，因为一个处理器可能会等待另一个处理器完成它的工作。

- GPU针对吞吐量进行了优化，并根据数据处理的最大速率进行优化。然而，这种快速处理是有代价的。由于用于缓存和控制逻辑的芯片面积更小，每个着色器内核的延迟通常比CPU处理器遇到的延迟要高得多。

- GPU将指令执行逻辑与数据分离，对固定数量的着色器程序同步执行相同命令，这种方式称为单指令多数据（single instruction multiple data,SIMD）。

- 每个片段的像素着色器调用称为线程，这种类型的线程不同于CPU线程。使用相同着色程序的线程被捆绑成组，NVIDIA称为warps，AMD称为wavefronts。假设我们有2000个线程要执行。NVIDIA gpu上的warps包含32个线程。这将产生2000÷32 = 62.5 warps，这意味着分配了63个warps，其中一个warp是半空的。

- 着色器程序的结构是影响效率的一个重要特性。一个主要因素是每个线程的寄存器使用量。着色器程序与每个线程关联所需的寄存器越多，可以驻留在GPU中的线程就越少，因此wraps也就越少。wraps 的短缺可能意味着无法通过交换减轻延迟。可使用的warp数量称为占用率。高占用率意味着有许多可用于处理的warp，因此处理器空闲的可能性较小。内存读取的频率也会影响延迟。另一个影响因素是由‘’if“语句和循环引起的动态分支。在着色器程序中遇到"if"语句，如果所有线程都求值并采用同一分支，则warp可以继续不需要考虑其他分支。然而如果一些甚至只有一个线程选择另一条路径，那么warp必须执行两个分支，丢弃每个特定线程中不需要的结果。这个问题称为线程发散，其中一些线程可能需要执行循环迭代，或者执行warp中的其他线程没有执行的“if”路径，而其他线程在此期间处于空闲状态。

![\img\in-post\rtr3\3-1](\img\in-post\rtr3\3-1.jpg)

原书图3.1，简化着色器执行示例。三角形的每个片元都是一个线程，组成了warp。每个warp简化显示为4个线程，实际上有32个线程。着色器程序有5条指令。四组GPU着色器处理器执行这些指令的第一个warp，直到“txr”命令检测到需要时间来获取它数据的情况。第二个warp是交换进来的着色程序的前三条指令，执行直到再次检测到停滞为止。在第三个warp交换并停滞后，交换到第一个warp并继续执行。如果此时它的“txr”命令的数据还没有返回，那么执行将真正停止，直到数据可用为止。每个warp依次完成。

### GPU渲染管线概述

![\img\in-post\rtr3\3-2](\img\in-post\rtr3\3-2.jpg)

原书图3.2，GPU渲染管线的实现。绿色阶段是完全可编程的，虚线表示为可选阶段。黄色阶段是可配置的，但是不可编程，例如各种混合模式可以在合并阶段设置。蓝色的阶段是完全固定的。

- GPU实现了第二章所描述的几何处理、光栅化、像素处理流水线。这些被划分为几个硬件阶段，具有不同程度的可操作性或可编程性（如图3.2所示）。注意这些物理阶段的划分与第二章中介绍的功能阶段有所不同。

- 这里描述的是逻辑模型，通过API程序暴露出来。这个逻辑管线的实现取决于硬件供应商。逻辑模型可以帮助你推断性能的影响因素，但不应该将其误认为GPU实际实现管线的方式。

- 顶点着色器是一个完全可编程的阶段，用于实现几何处理阶段。几何着色器是一个完全可编程的阶段，操作点、线或三角形上的顶点。它可以用于执行每个图元的着色操作，销毁图元或创建新图元。细分阶段和几何着色器是可选的，并不是所有GPU都支持它们，特别是在移动设备上。

### 可编程着色阶段

- 现代着色器程序使用统一的着色器设计。这意味着顶点、像素、几何和细分相关的着色器共享一个公共的编程模型。它们具有相同的指令集体系结构(instruction set architecture，ISA)。在DirectX中，实现该模型的处理器称为共着色器内核，具有这种内核的GPU具有统一的着色器体系结构。GPU可以根据自己的需要分配这些处理器，决定如何平衡负载。

- 着色器使用类c语言编程，比如DirectX使用HLSL(High-Level Shading Language),OpenGL使用GLSL(OpenGL Shading Language)。HLSL可以编译成汇编语言，也称为中间语言(intermediate language，IL)，以提供硬件独立性。

- 32位单精度浮点的标量和矢量是其基本数据类型，之后也支持32位整型和64位浮点型。浮点向量通常包含位置(xyzw)、法线、矩阵、颜色(rgba)或纹理坐标(uvwq)等数据。整数通常用于表示计数器、索引或位掩码。还支持综合数据类型，如结构体、数组和矩阵。

- 一个Draw Call会调用图形API来绘制一组图元，从而使图形管线执行并运行着色器。每个可编程着色阶段都有两种类型的输入：uniform 输入，值在一个draw call期间保持不变（但是可以在draw call间进行更改）；varying 输入，数据来自三角形的顶点或者光栅化阶段。例如像素着色器可以提供一个光源的颜色作为一个uniform值，三角形表面的位置随着像素的变化而变化（varying）。纹理是一种特殊的uniform输入，它曾经是应用于表面的彩色图像，但是现在可以看作是任何存储大量数据的数组。

- 底层虚拟机为不同类型的输入和输出提供特殊的寄存器。可用于常数的寄存器数量远远大于可用于不同输入或输出的寄存器。这是因为不同的输入和输出需要分别存储在每个顶点或像素上，统一的输入只存储一次并在一次draw call中的所有顶点或像素上重用。

![\img\in-post\rtr3\3-3](\img\in-post\rtr3\3-3.jpg)

原书图3.3，Shader Model 4.0下虚拟机架构和寄存器布局。每个资源旁边都显示了最大可用数量。三个数字从左到右分别是顶点、集合、像素着色器中的限制。

- 着色语言表示出了大多数常见的操作（比如加法乘法用运算符+和*来表示）。其余的操作有为GPU优化的函数比如atan(),dot(),log()等。更复杂的操作也存在于内部函数，比如向量归一化（vector normalization）、反射(reflection)、叉乘(cross product)、矩阵转置(matrix transpose)和行列式(determinant)等。

- 流控制指的是使用分支指令来改变代码执行流程的操作。这些指令用于实现高级语言结构如if和case语句，以及各种类型的循环。着色器支持两种类型的流控制。静态流控制是基于统一输入的值的。这意味着代码的流在调用时是常量。静态流控制的主要好处是允许在不同情况下使用相同的着色器（例如，不同数量的光源），所有的调用都采用相同的代码路径。动态流控制基于不同输入的值，这意味着每个片元可以独立地执行代码。这比静态流控制功能强大得多，但是会降低性能，特别是当着色器调用之间发生代码流变化时。

### 可编程着色和API的发展

可编程着色器框架思想可以追溯到1984年Cook的shade trees。

![\img\in-post\rtr3\3-4](\img\in-post\rtr3\3-4.jpg)

原书图3.4，一个简单的铜着色器和其对应的着色语言代码。

- 80年代中后期，RenderMan着色语言根据这个可编程着色框架思想开发出来，目前仍然广泛用于电影制作的渲染中，以及其他不断发展的规范，比如Open shading Language(OSL)项目。

![\img\in-post\rtr3\3-5](\img\in-post\rtr3\3-5.jpg)

原书图3.5，一些API和图形硬件的发布时间表

- 1996年10月1日，消费级图形硬件由3dfx Interactive公司推出。该硬件实现了一个固定功能的管道。在GPU原生支持可编程着色器之前，有一些通过多个渲染通道实现实时可编程着色的尝试。

- 1999年，《雷神 3：竞技场》脚本语言是在这个领域上第一个成功广泛商用的语言。NVIDIA的GeForce256是第一个被称为GPU的硬件，它是不可编程的，但它是可配置的。

- 2001 年，NVIDIA's GeForce 3 发布，它是第一个支持可编程顶点着色器的GPU，向DirectX 8.0 开放，并以扩展的形式提供给OpenGL。此时着色器不允许流控制(分支)，因此条件必须通过计算条件和在结果之间选择或插值来模拟。DirectX提出了着色器模型(SM)的概念，以区分具有不同着色器功能的硬件。

- 2002年，DirectX 9.0发布，包括了Shader Model 2.0，它支持真正的可编程顶点和像素着色。类似的功能也在OpenGL下使用各种扩展实现。增加了对任意依赖纹理读取和16位浮点值存储的支持，增加了对着色器资源（如指令、纹理、寄存器）的上限，因此着色器能进行更复杂的转换。还增加了流控制，着色器长度和复杂性的增加使得编程越来越麻烦。幸而着色编程语言HLSL也随着DirectX 9.0发布。这种着色语言是微软与英伟达合作开发的。大约在同一时间，OpenGL ARB(Architecture Review Board)发布了GLSL,这是一种和OpenGL相当类似的语言。这些语言在很大程度上受到C语言的语法和设计理念的影响，并包含了RenderMan着色语言中的元素。

- 2004年，Shader Model 3.0发布，添加了动态流控制，使得着色器更加强大。它还将可选功能进行了实现，进一步增加了资源上限，并在顶点着色器中添加了有限的纹理读取支持。

- 2005年以及2006年，微软和索尼分别推出了新一代游戏主机Xbox 360和PLAYSTATION 3，它们都配备了Shader Model 3.0级别的GPU。2006年底，任天堂的Wii发布，是最后一款值得注意的搭载固定功能管线GPU的主机。在当时上，纯粹的固定功能管线过时很久了。着色器语言已经发展到使用各种工具来创建和管理它们了。

![\img\in-post\rtr3\3-6](\img\in-post\rtr3\3-6.jpg)

原书图3.6，一个用于着色器设计的可视化着色器图形系统。各种操作都封装在左边的函数库中。当函数框被选择时，右图显示各种可调节的参数。每个函数框中的输入输出互相连接得到最终结果，如图中右下角显示。

- 2006年年底，Shader Model 4.0发布，包含于DirectX10.0中，引入了几个主要特性，比如几何着色器和流输出。Shader Model 4.0为所有着色器(顶点、像素和几何)提供了统一的编程模型，进一步增加了资源上限，并添加了对整数数据类型(包括位操作)的支持。OpenGL 3.3引入的GLSL 3.30中提供了一个类似的着色器模型。

- 2009年，DirectX 11和Shader Model 5.0发布，添加了细分着色器(tessellation stage shaders )和计算着色器(compute shader,也称为DirectCompute)。OpenGL在4.0版本中添加了细分曲面，在4.3版本中添加了计算着色器。

- 2013年，AMD公司引入了Mantle API。Mantle是与电子游戏开发商DICE合作开发的，其理念是去掉大部分图形驱动程序的开销，并将这种控制直接交给开发者。除了这种重构，还进一步支持有效的CPU多处理。这类新的API着重于大大减少CPU在驱动程序上花的时间。

- 2014年，苹果公司发布了自己的低开销API Metal。Metal首次出现在iPhone 5s和iPad Air等移动设备上，除了效率之外，减少CPU使用还可以省电，这是移动设备上的一个重要因素。这个API有自己的着色语言，用于图形和GPU计算程序。

- 2015年，微软发布DirectX 12。DirectX 12是对API的彻底重新设计，是一个更好地映射到现代GPU的架构。低开销驱动程序适用于CPU驱动程序成本导致瓶颈的应用程序，或者使用更多CPU处理器处理图形可以提高性能的应用程序。

- 2016年，AMD将Mantle技术工作交给了 Khronos Group，后者在2016年初发布了自己的新API Vulkan。与OpenGL一样，Vulkan也支持多个操作系统。Vulkan使用了一种新的高级中间语言SPIRV，它既用于着色器表示，也用于通用GPU计算。预编译着色器是可移植的，因此可以在任何支持所需功能的GPU上使用。Vulkan也可以用于非图形GPU计算，因为它不需要显示窗口。Vulkan与其他低开销驱动程序的一个显著区别是，它适用系统广泛，从工作站到移动设备。

- 在移动设备上通常使用OpenGL ES。“ES”代表嵌入式系统(Embedded Systems)，因为这个API是为移动端开发的。当时，标准OpenGL的一些调用结构相当笨重和缓慢，并且需要支持很少使用的功能。OpenGL ES 1.0与2003年发布，是OpenGL 1.3的精简版，描述了固定功能管线。虽然DirectX的发布与支持它们的图形硬件同步，但是为移动设备开发图形支持并不是以相同的方式进行的。例如，2010年发布的第一代iPad实现了OpenGL ES 1.1。2007年，OpenGL ES 2.0规范发布，提供可编程的着色器。它基于OpenGL 2.0，但没有固定的函数组件，因此不能向后兼容OpenGL ES 1.1。OpenGL ES 3.0于2012年发布，提供了多目标渲染(render targets)、纹理压缩(texture compression)、转换反馈(transform feedback)、实例化(instancing)以及更广泛的纹理格式和模式，以及着色语言的改进。OpenGL ES 3.1增加了计算着色器，3.2增加了几何和细分着色器等功能。

- OpenGL ES的一个分支是基于浏览器的API WebGL，通过JavaScript调用。该API的第一个版本于2011年发布，在大多数移动设备上都可以使用，因为它的功能相当于OpenGL ES 2.0。与OpenGL一样，使用扩展访问更高级的GPU特性。WebGL 2规范基于OpenGL ES 3.0。WebGL特别适合在课堂上进行特性试验或使用:

  - 它是跨平台的，适用于所有的个人电脑和几乎所有的移动设备。

  - 驱动程序由浏览器处理。即使一个浏览器不支持特定的GPU或扩展，通常另一个浏览器支持。

  - 代码是解释的，而不是编译的，开发只需要一个文本编辑器。

  - 大多数浏览器都内置了调试器，可以检查任何网站上运行的代码。

  - 程序可以通过上传到网站或Github来部署。

- 更高级的场景图和效果库，如three.js，为各种更复杂的效果(如阴影算法、后处理效果、基于物理的渲染和延迟渲染)提供了方便的代码访问。

### 顶点着色器

- 在顶点着色阶段之前发生了一些数据操作。比如在DirectX 中叫做输入装配(Input Assembler)的阶段，会将一些数据流组织在一起，以形成顶点和基元的集合，发送到管线。在输入装配中也支持执行实例化。这允许使用每个实例的不同数据多次绘制对象，所有这些数据都使用一个draw call。

### 细分阶段

### 几何着色器

### 像素着色器

### 合并阶段

### 计算着色器
